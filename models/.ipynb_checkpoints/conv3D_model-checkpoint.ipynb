{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## first run \n",
    "##pip install h5py==2.8.0\n",
    "##pip install tensorflow==1.5.0\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense,Dropout, Activation, Flatten, Conv3D, MaxPooling3D \n",
    "#from keras.regularizers import Regularizer\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.models import load_model\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model(model_para = [6, 12, 18, 18, 64, 0.01, 0.4,(5, 5, 5)],foldname = os.path.abspath('.') ):\n",
    "    # input image dimensions\n",
    "    \n",
    "    #img_rows, img_cols, img_depth = 49,39,38\n",
    "    # number of convolutional filters to use\n",
    "    conv_l2 = 0.008\n",
    "    \n",
    "    full_l2  = 0.3\n",
    "    # convolution kernel size\n",
    "    kernel_size = (3,3,3)\n",
    "    # size of pooling area for max pooling\n",
    "    pool_size = (2, 2, 2)\n",
    "\n",
    "    drop_out = (model_para[5], model_para[6])\n",
    "    \n",
    "    act_function = 'tanh'\n",
    "    \n",
    "    full_connect = model_para[4]\n",
    "    \n",
    "    nb_filters = (model_para[0], model_para[1], model_para[2], model_para[3])\n",
    "#    nb_filters = (5, 10, 15, 15)\n",
    "    l1_regularizer = 0.01\n",
    "    \n",
    "    l2_regularizer = full_l2\n",
    "    \n",
    "    nb_classes = 2\n",
    "    \n",
    "    #input_shape = (1, 40, 48, 48)\n",
    "    input_shape = (40, 48, 48, 1)\n",
    "    \n",
    "    #wr = WeightRegularizer(l1=l1_regularizer,l2=l2_regularizer)\n",
    "    kr = l1_l2(l1=l1_regularizer, l2=l2_regularizer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create cnn model\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    #keras.layers.Conv3D(filters, kernel_size, strides=(1, 1, 1), padding='valid', \n",
    "    #data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, \n",
    "    #kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, \n",
    "    #bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "   \n",
    "    #model.add(Conv3D(filters = 1,kernel_size = 3, strides = 1, activation = 'tanh', input_shape = (50, 41, 40, 1)))\n",
    "    \n",
    "    # need to specify data_format='channels_first' \n",
    "    \n",
    "    model.add(Conv3D(nb_filters[0], kernel_size[0], kernel_size[1],kernel_size[2],W_regularizer = l2(conv_l2),\n",
    "                                activation = act_function , input_shape=input_shape, data_format='channels_last'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=pool_size)) \n",
    "    \n",
    "    model.add(Dropout(drop_out[0]))\n",
    "\n",
    "    model.add(Conv3D(nb_filters[1], kernel_size[0], kernel_size[1], kernel_size[2],W_regularizer = l2(conv_l2),\n",
    "                                   activation = act_function))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Dropout(drop_out[0]))\n",
    "    \n",
    "    model.add(Conv3D(nb_filters[2], kernel_size[0], kernel_size[1], kernel_size[2],W_regularizer = l2(conv_l2),\n",
    "                                    activation = act_function))  \n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=pool_size))    \n",
    "\n",
    "    model.add(Dropout(drop_out[0]))\n",
    "    \n",
    "    \n",
    "    model.add(Conv3D(nb_filters[3], kernel_size[0], kernel_size[1], kernel_size[2],W_regularizer = l2(conv_l2),\n",
    "                            activation = act_function))\n",
    "    #model.add(MaxPooling3D(pool_size=pool_size))    \n",
    "\n",
    "    model.add(Dropout(drop_out[1]/2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #model.add(Dense(full_connect, W_regularizer = wr,activation = act_function))\n",
    "\n",
    "    model.add(Dropout(drop_out[1]))\n",
    "    \n",
    "    model.add(Dense(nb_classes,activation = act_function))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "    #model.add(Activation(act_function))\n",
    "    model.summary()\n",
    "\n",
    "    ADA = Adadelta(lr = 2.0, rho=0.95)\n",
    "\n",
    "    model.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer= ADA,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "\n",
    "##    save parameters of cnn model to .txt             \n",
    "    sname = 'model_parameter.txt'\n",
    "    full_namem = os.path.join(foldname,sname)\n",
    "    fm = open(full_namem,'w')\n",
    "    fm.write('************CNN model parameter************ '+'\\n')\n",
    "    fm.write('Number of Convolution layer :     '+str(len(nb_filters))+'\\n')\n",
    "    fm.write('Input shape :                     '+str(input_shape)+'\\n')\n",
    "    fm.write('Number of kernal per layer ï¼?    '+str(nb_filters)+'\\n')\n",
    "    fm.write('Kernel size per layer :           '+str(kernel_size)+'\\n')\n",
    "    fm.write('Pool size per layer :             '+str(pool_size)+'\\n')\n",
    "    fm.write('Activation function per layer :   '+act_function+'\\n')\n",
    "#    fm.write('Dropout rate :                    '+str(drop_out)+'\\n')\n",
    "    fm.write('Number of full-connect layer :    '+str(full_connect)+'\\n')\n",
    "    fm.write('Coefficient of L1 regularizer :   '+str(l1_regularizer)+'\\n')\n",
    "    fm.write('Coefficient of L2 regularizer :   '+str(l2_regularizer)+'\\n')\n",
    "    fm.write('Output :                          '+str(nb_classes)+' classes'+'\\n')\n",
    "    fm.close()\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(6, (3, 3, 3), activation=\"tanh\", input_shape=(40, 48, 4..., data_format=\"channels_last\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(12, (3, 3, 3), activation=\"tanh\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(18, (3, 3, 3), activation=\"tanh\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(18, (3, 3, 3), activation=\"tanh\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 38, 46, 46, 6)     168       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 19, 23, 23, 6)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 23, 23, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 17, 21, 21, 12)    1956      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 10, 10, 12)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 10, 10, 12)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 6, 8, 8, 18)       5850      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 4, 4, 18)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 4, 4, 18)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 1, 2, 2, 18)       8766      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 2, 2, 18)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 146       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 16,886\n",
      "Trainable params: 16,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "\n",
    "#save weights for initialization\n",
    "\n",
    "for ii in range(27):\n",
    "    weights_file_path = \"C:\\\\Users\\\\Reid\\\\Desktop\\\\dataSciPrinciples\\\\finalProj\\\\Alz-Finders\\\\models\\\\model_weights\\\\saved_weights_\" + str(ii) + \".h5\"\n",
    "    model.save(weights_file_path)\n",
    "    del model \n",
    "    model = load_model(weights_file_path)\n",
    "    \n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for visualizing\n",
    "\n",
    "\n",
    "\n",
    "if 0:\n",
    "    def show_slices(slices):\n",
    "        \"\"\" Function to display row of image slices \"\"\"\n",
    "        fig, axes = plt.subplots(1, len(slices))\n",
    "        for i, slice in enumerate(slices):\n",
    "            axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "\n",
    "    slice_0 = img_data[50, :, :]\n",
    "    slice_1 = img_data[80, :, :]\n",
    "    slice_2 = img_data[100, :, :]\n",
    "    show_slices([slice_0, slice_1, slice_2])\n",
    "    plt.suptitle(\"first dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "    #so the first dimension slices from your right ear to your left ear\n",
    "\n",
    "\n",
    "    slice_0 = img_data[:, 20, :]\n",
    "    slice_1 = img_data[:, 25, :]\n",
    "    slice_2 = img_data[:, 35, :]\n",
    "    slice_3 = img_data[:, 45, :]\n",
    "    slice_4 = img_data[:, 50, :]\n",
    "    slice_5 = img_data[:, 55, :]\n",
    "    slice_6 = img_data[:, 60, :]\n",
    "    slice_7 = img_data[:, 70, :]\n",
    "    slice_8 = img_data[:, 75, :]\n",
    "    slice_9 = img_data[:, 80, :]\n",
    "    slice_10 = img_data[:, 85, :]\n",
    "    slice_11 = img_data[:, 90, :]\n",
    "\n",
    "\n",
    "\n",
    "    show_slices([slice_0, slice_1, slice_2, slice_3])\n",
    "    plt.suptitle(\"second dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    show_slices([slice_4, slice_5, slice_6, slice_7])\n",
    "    plt.suptitle(\"second dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    show_slices([slice_8, slice_9, slice_10, slice_11])\n",
    "    plt.suptitle(\"second dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "    #so the second dimension slices from the back of the head to the front of the head\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    slice_0 = img_data[:, :, 20]\n",
    "    slice_1 = img_data[:, :, 30]\n",
    "    slice_2 = img_data[:, :, 40]\n",
    "    slice_3 = img_data[:, :, 50]\n",
    "    slice_4 = img_data[:, :, 60]\n",
    "    slice_5 = img_data[:, :, 70]\n",
    "    slice_6 = img_data[:, :, 80]\n",
    "    slice_7 = img_data[:, :, 90]\n",
    "    slice_8 = img_data[:, :, 100]\n",
    "    slice_9 = img_data[:, :, 110]\n",
    "    slice_10 = img_data[:, :, 120]\n",
    "    slice_11 = img_data[:, :, 130]\n",
    "\n",
    "\n",
    "    show_slices([slice_0, slice_1, slice_2, slice_3])\n",
    "    plt.suptitle(\"third dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    show_slices([slice_4, slice_5, slice_6, slice_7])\n",
    "    plt.suptitle(\"third dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    show_slices([slice_8, slice_9, slice_10, slice_11])\n",
    "    plt.suptitle(\"third dimension slices\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    #so the third dimension slices horizontally from bottom of the brain up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 192, 192)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(160, 192, 192)\n",
      "<class 'numpy.ndarray'>\n",
      "(80, 96, 96)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4617 - acc: 0.0000e+00\n",
      "[[0.739218   0.26078203]]\n"
     ]
    }
   ],
   "source": [
    "# do the file traversal\n",
    "# do the downsample\n",
    "# do the fit\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#C:\\Users\\Reid\\Desktop\\dataSciPrinciples\\finalProj\\ADNI_Preproc\\ADNI\\AD\\036_S_1001\\2006-11-20_09_21_45.0.nii\n",
    "\n",
    "adni_file_path = \"C:\\\\Users\\\\Reid\\\\Desktop\\\\dataSciPrinciples\\\\finalProj\\\\ADNI_Preproc\"\n",
    "spec_file_path = \"ADNI\\\\AD\\\\036_S_1001\\\\2006-11-20_09_21_45.0.nii\"\n",
    "full_file_path = os.path.join(adni_file_path, spec_file_path)\n",
    "\n",
    "img = nib.load(full_file_path)\n",
    "img_data = img.get_fdata()\n",
    "\n",
    "print(img.shape)\n",
    "print(type(img))\n",
    "img_np = np.array(img.dataobj)\n",
    "print(img_np.shape)\n",
    "print(type(img_np))\n",
    "\n",
    "\n",
    "img_np_ds = img_np[::2,::2,::2]\n",
    "print(img_np_ds.shape)\n",
    "\n",
    "def get_patch(input_3D, patch_idx):\n",
    "    if (patch_idx < 0 | patch_idx > 26):\n",
    "        print(\"You have passed an incorrect patch index to get patch: \"+ str(patch_idx))\n",
    "    dim1_start_idxs = [0, 20, 40] \n",
    "    dim1_end_idxs =[40, 60, 80]\n",
    "    dim2_start_idxs = [0, 24, 48] \n",
    "    dim2_end_idxs =[48, 72, 96]\n",
    "    dim3_start_idxs = [0, 24, 48]\n",
    "    dim3_end_idxs = [48, 72, 96]\n",
    "    ii = int(patch_idx / 9)\n",
    "    jj = int( (patch_idx %9)  / 3)\n",
    "    kk = int(patch_idx % 3)\n",
    "    return input_3D[dim1_start_idxs[ii]:dim1_end_idxs[ii],dim2_start_idxs[jj]:dim2_end_idxs[jj],dim3_start_idxs[kk]:dim3_end_idxs[kk]]\n",
    "\n",
    "\n",
    "def get_sampleXY(path, isAD, patch_idx):\n",
    "    img = nib.load(full_file_path)\n",
    "    img_data = img.get_fdata()\n",
    "    img_np = np.array(img.dataobj)\n",
    "    img_np_ds = img_np[::2,::2,::2]\n",
    "    x = get_patch(img_np_ds, patch_idx)\n",
    "    #(batches, x, y, z, channels)\n",
    "    x = x.reshape((1, 40, 48, 48, 1))\n",
    "    y = np.array([[int(isAD), 1-int(isAD)]])\n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#patch_0 = get_patch(img_np_ds, 0)\n",
    "#patch_0 = patch_0.reshape((1, 40, 48, 48, 1))\n",
    "#print(patch_0.shape)\n",
    "\n",
    "#patch_label = np.array([[1,0]])\n",
    "#print(patch_label)\n",
    "#print(patch_label.shape)\n",
    "#result = model.predict(patch_0)\n",
    "\n",
    "\n",
    "sample_x, sample_y = get_sampleXY(full_file_path, True, 0)\n",
    "\n",
    "#model.fit(x=sample_x, y=sample_y, epochs=25) \n",
    "model.fit(x= sample_x, y=sample_y, epochs=1)\n",
    "\n",
    "result = model.predict(sample_x)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ad_nii_IDs():\n",
    "    ad_nii_ids = []\n",
    "    patients_path = 'C:\\\\Users\\\\Reid\\\\Desktop\\\\dataSciPrinciples\\\\finalProj\\\\ADNI_Preproc\\\\ADNI\\\\AD\\\\'\n",
    "    for patient_folder in os.listdir(patients_path):\n",
    "        nii_path = os.path.join(patients_path, patient_folder)\n",
    "        for nii in os.listdir(nii_path):\n",
    "            ad_nii_ids.append(nii)\n",
    "    #print(len(ad_nii_ids))\n",
    "    #print(ad_nii_ids)\n",
    "    return ad_nii_ids\n",
    "    \n",
    "ad_nii_IDs = get_ad_nii_IDs()    \n",
    "#print(len(ad_nii_IDs))\n",
    "#print(ad_nii_IDs)\n",
    "\n",
    "\n",
    "def get_nc_nii_IDs():\n",
    "    nc_nii_ids = []\n",
    "    patients_path = 'C:\\\\Users\\\\Reid\\\\Desktop\\\\dataSciPrinciples\\\\finalProj\\\\ADNI_Preproc\\\\ADNI\\\\CN\\\\'\n",
    "    for patient_folder in os.listdir(patients_path):\n",
    "        nii_path = os.path.join(patients_path, patient_folder)\n",
    "        for nii in os.listdir(nii_path):\n",
    "            nc_nii_ids.append(nii)\n",
    "    #print(len(ad_nii_ids))\n",
    "    #print(ad_nii_ids)\n",
    "    return nc_nii_ids\n",
    "\n",
    "nc_nii_IDs = get_nc_nii_IDs()    \n",
    "#print(len(nc_nii_IDs))\n",
    "#print(nc_nii_IDs)\n",
    "\n",
    "#list(set(ad_nii_IDs).intersection(set(nc_nii_IDs)))\n",
    "\n",
    "\n",
    "def create_train_test_split_nii_ids(ad_nii_IDs, nc_nii_IDs):\n",
    "    randVec = np.random.rand( (len(ad_nii_IDs) + len(nc_nii_IDs), 1) )\n",
    "    #decide 80% for training, 20% for testing\n",
    "    train_indices = randVec < 0.8\n",
    "    test_indices = randVec >= 0.8\n",
    "    \n",
    "    train_ad_IDs = ad_nii_IDs[train_indices]\n",
    "    train_nc_IDs = nc_nii_IDs[train_indices]\n",
    "    test_ad_IDs = ad_nii_IDs[test_indices]\n",
    "    test_nc_IDs = nc_nii_IDs[test_indices]\n",
    "    \n",
    "    train_IDs = {'AD':train_ad_IDs, 'NC': train_nc_IDs }\n",
    "    test_IDs = {'AD':test_ad_IDs, 'NC': test_nc_IDs }\n",
    "    \n",
    "    return train_IDs, test_IDs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
